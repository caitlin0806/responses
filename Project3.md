For this project, we were given 10,000 images that were 480x480 pixels of Korle Gonno, Accra. The images were of population counts in the town. We were also given a csv file that contained an array of labels that corresponded to each image and the second column provided counts of the people that resided in each particular image. The data is from September 2005. 

The first thing I did was unzip the 4 accra folders and put the first 3 folders all in one folder that was labeled my training. I kept the 4th folder the same and called it my testing. So, my training was 90%. I then made code to import my data that allowed a pathway for my training folder, testing folder, and labels csv file. Now I have my training data, training labels, testing data, and testing labels. I originally tried to divide my training images and testing images by 255.0 but my computer wouldn’t allow me because it said that I did not have enough storage. So, I just skipped trying to standardize it unfortunately. Next, I started to build a DNN model. I used a Sequential keras model that included a flatten layer, a dense layer with 128 neurons and a relu activation, another dense layer with 64 neurons and relu activation, and then one last dense layer with 1 neuron. I used relu for my activation because relu allows for faster and more effective training of deep neural networks on larger datasets and our dataset is pretty large. I then compiled the model by using an RMSprop optimizer. I chose RMSprop as the optimizer because Rprop doesn’t work well with large datasets and RMSprop is similar to Adagrad as it still keeps the same estimate of squared gradients, but instead of letting that estimate continually accumulate over training, it keeps a moving average of it. I chose mse as my loss function because it ensures the training model has no outlier predictions with huge errors. For the metric I chose mae and mse instead of accuracy because accuracy wouldn’t be a good measure for this kind of data. Instead, the goal was to decrease mae and mse as much as possible. Next, I fit the model using the training images and training labels with 100 epochs, 90 steps per epoch, and 100 batch size. This combination gave me the best output where the mse and mae was at its lowest. My mae ended up being 35.5113 and my mse ended up being 1591.2771. Next, I evaluated my model using the testing images and testing labels that consisted of 1000 pictures and it gave me mae of 47.1175 and mse of 2493.1792. Watching the epochs run, my loss accuracy would drop tremendously from the start and then start to fluctuate as it went on. The loss increasing after decreasing was a strong indicator that the model is over fit. My mae would also increase after decrease and continue to fluctuate, so that was also an indicator of overfitting. After being happy with my results for my DNN model, I decided to make a CNN model. 

For the CNN model I used a Sequential model, I had 3 Conv2D layers that used the relu activation, 3 MaxPooling2D layers, 1 flatten layer, and 3 dense layers. When I went to compile it, I kept my arguments the same as the DNN model. Then, I fit the model to the training images and training labels using 5 epochs, 90 steps per epoch, and 100 batch size. When I first ran this code my computer CRASHED. It restarted and I lost everything. Luckily, I was writing this markup on a pdf file at first and it saved everything I wrote above. Once I finally managed to get everything back I reran the code and got   

