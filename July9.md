1.	TF Hub is a library and platform used for transfer learning. It’s a library for publication, discovery, and consumption of reusable parts of machine learning models. We used it to for the first layer to create a Keras layer that utilizes a model from the hub to embed sentences. 
2.	The optimizer’s purpose is to minimize loss and the script used adam.  The loss function used the binary_crossentropy since it deals with probabilities better. When I ran the code my output was: loss: 0.327,  accuracy: 0.851. So, my model was 85% accurate. 
3.	The dot represents the training loss and the line represents the validation loss. Training and validation loss both decrease as epochs increases. The graph compares the loss of data the model was built on and that training data. Validation loss starts leveling off around 6 epochs. Training loss continues to decrease to 0 as epochs increase. (figure 1)
4.	The dot represents the training accuracy and the line represents the validation accuracy. As the epochs increase both the accuracies increases. The training accuracy is greater than the validation accuracy after 5 epochs. Both the graphs represents an overfit model since the model represents the training data better. (figure 2)

![Figure_1](https://user-images.githubusercontent.com/67920437/87229358-61f11180-c375-11ea-9f54-75b97e3d66b4.png)
![Figure_2](https://user-images.githubusercontent.com/67920437/87229360-64ec0200-c375-11ea-8e3e-6b8735386582.png)
